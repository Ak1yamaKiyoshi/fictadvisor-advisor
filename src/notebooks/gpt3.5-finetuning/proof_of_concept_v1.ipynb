{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimer \n",
    "\n",
    "Спочатку трошки про мене: я джун у фронтенді дев відділу ФІОТ. <br> \n",
    "Мій досвід не великий - щось довкола 10 тасків, де суттєвих, що потребують досвіду ( feature ) меншість. <br> \n",
    "Всі твердження виходять лише з мого досвіду. \n",
    "\n",
    "# Speeding up work at the cost of stupidity.  \n",
    "Я лінивий. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Що ж. Для кінцевого результату нам важливо декілька речей\n",
    " - Те, як правильно модель буде розуміти поставлені задачі (bufix, enhancement, feature, etc.) \n",
    " - Планування - як добре модель може розписати покрокове рішення задачі \n",
    " - Написання коду - наскільки він валідний \n",
    "\n",
    "<br> Щоб досягти цього  існують декілька варіантів:\n",
    " 1. запхати весь код проєкту у модель та сподіватися на краще \n",
    " 2. розібрати декілька іш'юсів з покроковим поясненням кожної дії \n",
    "або ж обидва пункти одразу \n",
    "\n",
    "<br> Що важливо? \n",
    "1. Якщо модель не знатиме вже написаного коду, вона не зможе давати точні відповіді та вказувати на конкретні помилки / виправлення. Таким чином її функціонал обмежується до абстрактних порад на основі вже вивченого з інтернету коду. \n",
    "Це проблема, яку я намагаюсь вирішити, оскільки такий ефект рівносильний тому, щоб запхати код у чатгпт без будь-яких додаткових дій. \n",
    "\n",
    "2. У більшості випадків, модель так чи інакше не здатна вигадати геніальне рішення для нової фічі. ( хоча шаблонні рішення повинні даватись легко )\n",
    "З цим нічого не зробиш, оскільки у людського розробника досвіду куди більше, та людина врешті-решт може креативно мислити та комунікувати."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед тим, як переходити до створення датасету, давайте проведемо невеличке дослідження, все ж, ми тут датасаєнсом займаємось! <br>\n",
    "З [треду](https://www.reddit.com/r/ChatGPT/comments/11ax0cy/is_it_possible_to_give_chatgpt_whole_of_my/) на реддіті, який чудово описує перше питання яке постало перед нами. \n",
    "<br>У мене вийшло дістати трошки корисної інформації, а саме те, що велика кількість коду не вміститься у короткостроковій пам'яті гпт, для цього існуює embedingsAPI\n",
    "<br>А також та знайшов [cookbook](https://cookbook.openai.com/examples/get_embeddings_from_dataset) яким демонструє як отримати embeddings з датасету "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Що ж таке ці embeddings, та з чого вони зліплені? [opeanAI](https://platform.openai.com/docs/guides/embeddings#:~:text=OpenAI's%20text%20embeddings%20measure%20the,related%20text%20strings%20are%20recommended)\n",
    "<br> Одразу відповідаючи на це питання: це векторна репрезентація слів, де вектор не тільки позначає саме по собі слово, а також його важливість та як воно відноситься до інших слів. \n",
    "<br> Те, як слова відносяться одне до одного визначити просто: це відстань між їх векторами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А тепер давайте спробуємо! \n",
    "<br> Для наглядності та економії часу у прикладі я буду використовувати реальний код проєкту."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спочатку імпортуємо всі необхідні бібліотеки "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "#from utils.embeddings_utils import get_embedding\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import openai\n",
    "load_dotenv('../../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визначемо шлях завантаження, посилання на сам репозиторій та файл який ми будемо використовувати для прикладу \n",
    "<br> Зокрема зазначимо модель, яку будемо використовувати "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://github.com/fictadvisor/fictadvisor-web.git\" \n",
    "PATH = '../../../assets/repositories/frontend/'\n",
    "FILE = 'src/components/pages/personal-teacher-page/PersonalTeacherPage.tsx'\n",
    "MODEL =  \"text-embedding-ada-002\"\n",
    "GPTMODEL = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_clone = False # Щоб не клонувати кожен раз репозиторій, коли він вже є, \n",
    "if to_clone:\n",
    "    directory = '../assets/repositories/frontend/'\n",
    "    if os.path.exists(directory):\n",
    "        shutil.rmtree(directory)\n",
    "    subprocess.run([\"git\", \"clone\", URL, PATH])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаємо наш файл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Оскільки ми працюємо з трансформером, кожне слово повинно бути перетворене на токен ( у нашому випадку, у вигляді вектору ), оскільки мережі не розуміють слів напряму. \n",
    "<br> Існує багато способів токенізації, але зараз ми просто використаємо той, що пропонують самі openAI. \n",
    "<br> Чому це для нас взагалі важливо? \n",
    "<br> У кожної з запропонованих моделей на сьогоднішній день існує максимальна кількість токенів, що є для нас проблемою.\n",
    "<br> Але не тільки у цьому справа: за велику кількість токенів доведеться і більше платити :>\n",
    "\n",
    "<br> Годі слів, час пробувати!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для початку відкриємо не великий за змістом файл, скоріше серендій з оглядкою на мій досвід."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import {\n",
      "  createContext,\n",
      "  Dispatch,\n",
      "  FC,\n",
      "  SetStateAction,\n",
      "  useEffect,\n",
      "  useState,\n",
      "} from 'react';\n",
      "import { useRouter } from 'next/router';\n",
      "\n",
      "import Breadcrumbs from '@/components/common/ui/breadcrumbs';\n",
      "import PersonalTeacherCard from '@/components/common/ui/cards/personal-teacher-card';\n",
      "import Progress from '@/components/common/ui/progress';\n",
      "import PersonalTeacherTabs from '@/components/pages/personal-teacher-page/personal-teacher-tabs';\n",
      "import styles from '@/components/pages/personal-teacher-page/PersonalTeacherPage.module.scss';\n",
      "import {\n",
      "  PersonalTeacherPageProps,\n",
      "  TeachersPageTabs,\n",
      "} from '@/components/pages/personal-teacher-page/utils';\n",
      "import useTabState from '@/hooks/use-tab-state';\n",
      "import useToast from '@/hooks/use-toast';\n",
      "import { Teacher } from '@/types/teacher';\n",
      "\n",
      "// TODO: move context to separate folder, move types to separate folder\n",
      "export interface TeacherContext {\n",
      "  floatingCardShowed: boolean;\n",
      "  setFloatingCardShowed: Dispatch<SetStateAction<boolean>>;\n",
      "  teacher: Teacher;\n",
      "}\n",
      "\n",
      "export const teacherContext = createContext<TeacherContext>({\n",
      "  floatingCardShowed: false,\n",
      "  setFloatingCardShowed: () => {},\n",
      "  teacher: {} as Teacher,\n",
      "});\n",
      "\n",
      "const PersonalTeacherPage: FC<PersonalTeacherPageProps> = ({\n",
      "  isLoading,\n",
      "  isError,\n",
      "  data,\n",
      "  teacher,\n",
      "  query,\n",
      "  teacherId,\n",
      "}) => {\n",
      "  const router = useRouter();\n",
      "  const { push } = router;\n",
      "  const toast = useToast();\n",
      "  const [floatingCardShowed, setFloatingCardShowed] = useState(false);\n",
      "\n",
      "  const { tab } = query;\n",
      "\n",
      "  const [index, setIndex] = useState<TeachersPageTabs>(\n",
      "    TeachersPageTabs.GENERAL,\n",
      "  );\n",
      "\n",
      "  const handleChange = useTabState({ tab, router, setIndex });\n",
      "\n",
      "  useEffect(() => {\n",
      "    if (isError) {\n",
      "      toast.error('Куди ти лізеш, цієї людини не існує');\n",
      "      void push('/teachers');\n",
      "    }\n",
      "  }, [isError, push]);\n",
      "\n",
      "  if (!data) return null;\n",
      "  return (\n",
      "    <teacherContext.Provider\n",
      "      value={{\n",
      "        floatingCardShowed,\n",
      "        setFloatingCardShowed,\n",
      "        teacher,\n",
      "      }}\n",
      "    >\n",
      "      <div className={styles['personal-teacher-page']}>\n",
      "        {isLoading ? (\n",
      "          <div className={styles['personal-teacher-page-content']}>\n",
      "            <div className={styles['loader']}>\n",
      "              <Progress />\n",
      "            </div>\n",
      "          </div>\n",
      "        ) : (\n",
      "          !isError && (\n",
      "            <div className={styles['personal-teacher-page-content']}>\n",
      "              <Breadcrumbs\n",
      "                sx={{ margin: '16px 0px 16px 0px' }} //TODO move inline styles when refactor\n",
      "                items={[\n",
      "                  {\n",
      "                    label: 'Головна',\n",
      "                    href: '/',\n",
      "                  },\n",
      "                  { label: 'Викладачі', href: '/teachers' },\n",
      "                  {\n",
      "                    label: `${teacher.lastName} ${teacher.firstName} ${teacher.middleName}`,\n",
      "                    href: `/teachers/${teacherId}`,\n",
      "                  },\n",
      "                ]}\n",
      "              />\n",
      "              <div className={styles['card-wrapper']}>\n",
      "                <PersonalTeacherCard {...teacher} />\n",
      "              </div>\n",
      "              <div className={styles['tabs']}>\n",
      "                <PersonalTeacherTabs\n",
      "                  data={data}\n",
      "                  tabIndex={index}\n",
      "                  handleChange={handleChange}\n",
      "                  teacher={teacher}\n",
      "                />\n",
      "              </div>\n",
      "            </div>\n",
      "          )\n",
      "        )}\n",
      "      </div>\n",
      "    </teacherContext.Provider>\n",
      "  );\n",
      "};\n",
      "export default PersonalTeacherPage;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(PATH + FILE, 'r') as file:\n",
    "    filedata = file.read()\n",
    "print(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Та порахуємо скільки буде коштувати запхати його у нашу модель! ( багато ) ( бюджет СР не резиновий )\n",
    "<br> Для початку завантажимо токенайзер для нашої моделі"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "# Downloading encodings for our model \n",
    "encoding = tiktoken.encoding_for_model(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_tokens(text):\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "count_tokens(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "744 Токени це велике число, не підйомне для мого гаманця, враховуючи що на проєкті fictadvisor більш ніж 950 файлів! \n",
    "<br> Давайде дізнаємось його ціну, можливо все не так погано"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "744 tokens for 0.004464$\n"
     ]
    }
   ],
   "source": [
    "def calculate_price(tokens):\n",
    "    \"\"\" \n",
    "    Model            Training                Input usage             Output usage\n",
    "    gpt-3.5-turbo    $0.0080 / 1K tokens\t $0.0030 / 1K tokens     $0.0060 / 1K tokens\n",
    "    \"\"\"\n",
    "    return tokens/1000*0.0060\n",
    "\n",
    "print(f\"{count_tokens(filedata)} tokens for {calculate_price(count_tokens(filedata))}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отже, багатенько, як на один файл. Пропоную порахувати скільки коштувало б скормити весь код fictadvisor frontend нашій моделі! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 36302884\n",
      " Total amount of files: 1024\n",
      " Average tokens per file: 35452.03515625\n",
      " Cost for all files: 217.817304$\n",
      " Cost per file: 0.2127122109375$\n"
     ]
    }
   ],
   "source": [
    "def tokens_in_each_file(directory):\n",
    "    total_tokens = 0\n",
    "    num_files = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "                filedata = file.read()\n",
    "            tokens = count_tokens(filedata)\n",
    "            total_tokens += tokens\n",
    "            num_files += 1\n",
    "    return  {'total_tokens': total_tokens, 'total_files': num_files} \n",
    "\n",
    "\n",
    "data = tokens_in_each_file(PATH) \n",
    "print(\n",
    "    f\"Total tokens: {data['total_tokens']}\" \n",
    "    + f\"\\n Total amount of files: {data['total_files']}\" \n",
    "    + f\"\\n Average tokens per file: {data['total_tokens'] / data['total_files'] }\"\n",
    "    + f\"\\n Cost for all files: {calculate_price(data['total_tokens'])}$\"\n",
    "    + f\"\\n Cost per file: {calculate_price(data['total_tokens']) / data['total_files']}$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "217 Доларів, що ж, я не можу собі дозволити таке задоволення. Треба трошки подумати!\n",
    "<br> Перш за все, варто зауважити, що наведений код бере абсолютно всі файли які є у проєкті, це можуть бути і картинки також, а картинки можуть займати дуже багато місця\n",
    "<br> Окрім  того, код не прибирає імпорти, які є у кожному файлі, і їх на справді дуже багато. Для тренування це не така важлива інформація, а ось грошей тягне багато. \n",
    "<br> Далі: пробіли, код не розділяється на слова, тому зайві пробіли можуть бути токенізовані, цього теж слід уникати \n",
    "<br> Тому давайте перерахуємо вартість!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 332705\n",
      " Total amount of files: 897\n",
      " Average tokens per file: 370.9085841694537\n",
      " Cost for all files: 1.99623$\n",
      " Cost per file: 0.0022254515050167223$\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_tokens_per_file(directory):\n",
    "    total_tokens = 0\n",
    "    num_files = 0\n",
    "    for dirpath, dirnames, filenames in os.walk(directory):\n",
    "        for filename in filenames:\n",
    "            # skip non-js/ts files\n",
    "            if not (filename.endswith('.js') or filename.endswith('.jsx') or filename.endswith('.ts') or filename.endswith('.tsx')):\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(dirpath, filename)\n",
    "            with open(file_path, 'r', encoding='ISO-8859-1') as file:\n",
    "                filedata = file.readlines()\n",
    "            # skip imports and delete unnecessary spaces\n",
    "            \n",
    "            filedata = ''.join([line for line in filedata if 'import' not in line])\n",
    "            filedata = ' '.join(word.strip() for line in filedata.split() for word in line.split())\n",
    "            \n",
    "            tokens = count_tokens(filedata)\n",
    "            total_tokens += tokens\n",
    "            num_files += 1\n",
    "    return {'total_tokens': total_tokens, 'total_files': num_files}\n",
    "\n",
    "data = calculate_average_tokens_per_file(PATH) \n",
    "print(\n",
    "    f\"Total tokens: {data['total_tokens']}\" \n",
    "    + f\"\\n Total amount of files: {data['total_files']}\" \n",
    "    + f\"\\n Average tokens per file: {data['total_tokens'] / data['total_files'] }\"\n",
    "    + f\"\\n Cost for all files: {calculate_price(data['total_tokens'])}$\"\n",
    "    + f\"\\n Cost per file: {calculate_price(data['total_tokens']) / data['total_files']}$\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Що ж, добре, той факт, що ми не розоримося на цьому проєкті не може не радувати.  \n",
    "<br> Давайте все-ж таки спробуємо зробити з цього embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для порівняння, попросимо зробити це завдання нашу модель до її файнтюнінгу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how do i do PersonalTeacherPage using React, Next, MUI for my website?\"\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{query}\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To create a PersonalTeacherPage using React, Next.js, and Material-UI (MUI) for your website, you can follow these steps:\n",
      "\n",
      "Step 1: Set up your development environment\n",
      "- Make sure you have Node.js and npm installed on your machine.\n",
      "\n",
      "Step 2: Create a new Next.js project\n",
      "- Open your terminal and run the following command to create a new Next.js project: \n",
      "```\n",
      "npx create-next-app personal-teacher-page\n",
      "```\n",
      "\n",
      "Step 3: Install Material-UI\n",
      "- Navigate to your project directory:\n",
      "```\n",
      "cd personal-teacher-page\n",
      "```\n",
      "- Run the following command to install Material-UI:\n",
      "```\n",
      "npm install @material-ui/core\n",
      "```\n",
      "\n",
      "Step 4: Create the PersonalTeacherPage component\n",
      "- Inside the \"pages\" directory of your project, create a new file called \"PersonalTeacherPage.js\".\n",
      "- Import React and Material-UI components in the file:\n",
      "```javascript\n",
      "import React from 'react';\n",
      "import { makeStyles } from '@material-ui/core/styles';\n",
      "import Container from '@material-ui/core/Container';\n",
      "import Typography from '@material-ui/core/Typography';\n",
      "```\n",
      "- Define the styles for your component using the makeStyles function:\n",
      "```javascript\n",
      "const useStyles = makeStyles(theme => ({\n",
      "  root: {\n",
      "    margin: theme.spacing(2)\n",
      "  },\n",
      "  title: {\n",
      "    marginBottom: theme.spacing(2)\n",
      "  }\n",
      "}));\n",
      "```\n",
      "- Create the PersonalTeacherPage component:\n",
      "```javascript\n",
      "const PersonalTeacherPage = () => {\n",
      "  const classes = useStyles();\n",
      "\n",
      "  return (\n",
      "    <Container maxWidth=\"sm\" className={classes.root}>\n",
      "      <Typography variant=\"h4\" className={classes.title}>\n",
      "        Personal Teacher Page\n",
      "      </Typography>\n",
      "      {/* Add your content here */}\n",
      "    </Container>\n",
      "  );\n",
      "}\n",
      "\n",
      "export default PersonalTeacherPage;\n",
      "```\n",
      "\n",
      "Step 5: Modify the index.js file\n",
      "- Open the \"pages/index.js\" file and remove its content.\n",
      "- Import the PersonalTeacherPage component:\n",
      "```javascript\n",
      "import PersonalTeacherPage from './PersonalTeacherPage';\n",
      "```\n",
      "- Replace the default export statement with PersonalTeacherPage:\n",
      "```javascript\n",
      "export default PersonalTeacherPage;\n",
      "```\n",
      "\n",
      "Step 6: Start the development server\n",
      "- Run the following command in your terminal to start the development server:\n",
      "```\n",
      "npm run dev\n",
      "```\n",
      "\n",
      "Now you have a basic PersonalTeacherPage component using React, Next.js, and Material-UI. You can customize the component and add your content as needed.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Щож, очікувано, що він не знає відповіді на це питання\n",
    "<br> Саме час це виправити!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "optimized = filedata\n",
    "optimized = ''.join([line for line in optimized.split(\"\\n\") if 'import' not in line])\n",
    "optimized = ' '.join(word.strip() for line in optimized.split() for word in line.split())\n",
    "\n",
    "sample = {\"messages\": \n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"\"}, \n",
    "    {\"role\": \"user\", \"content\": 'how do i do PersonalTeacherPage using React, Next, MUI for my website? Assume that i alrready have all needed components'},\n",
    "    {\"role\": 'assistant', 'content': optimized}\n",
    "]}\n",
    "\n",
    "samples = []\n",
    "for i in range(10):\n",
    "    samples.append(sample)\n",
    "\n",
    "def dicts_to_jsonl(data_list: list, filename: str) -> None:\n",
    "    \"\"\"Save a list of dicts to a jsonl file.\"\"\"\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for entry in data_list:\n",
    "            json.dump(entry, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "dicts_to_jsonl(samples, 'sample.jsonl')\n",
    "dataset_filepath = 'sample.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-NSX1fdKKMbDXxuGBGDUDrrWo\n",
      "file-dItB0EeI067892SY1jkCsMi5\n"
     ]
    }
   ],
   "source": [
    "file = client.files.create(\n",
    "  file=open(\"sample.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "print(file.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-omn6mq7HLMo4AfsodeVmm6bI\n",
      "validating_files\n",
      "FineTuningJob(id='ftjob-omn6mq7HLMo4AfsodeVmm6bI', created_at=1703167316, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-ptYJ2wDw5nK1CjWbG0joWavk', result_files=[], status='validating_files', trained_tokens=None, training_file='file-dItB0EeI067892SY1jkCsMi5', validation_file=None)\n"
     ]
    }
   ],
   "source": [
    "suffix_name = \"fictadvisor-advisor-proof-of-concept\"\n",
    "job = client.fine_tuning.jobs.create(\n",
    "  training_file=file.id,\n",
    "  #validation_file=filev.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "print(job.id)\n",
    "print(job.status)\n",
    "print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created fine-tuning job: ftjob-omn6mq7HLMo4AfsodeVmm6bI\n",
      "Validating training file: file-dItB0EeI067892SY1jkCsMi5\n",
      "Files validated, moving job to queued state\n",
      "Fine-tuning job started\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.list_events(job.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)\n",
    "# here model should be trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model ID: ft:gpt-3.5-turbo-0613:personal::8YE0sAwS\n"
     ]
    }
   ],
   "source": [
    "# Getting model id on end of training \n",
    "response = openai.fine_tuning.jobs.retrieve(job.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "\n",
    "if fine_tuned_model_id is None: \n",
    "    raise RuntimeError(\"Fine-tuned model ID not found. Your job has likely not been completed yet.\")\n",
    "\n",
    "print(\"Fine-tuned model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "createContext, Dispatch, FC, SetStateAction, useEffect, useState,} from 'react'; PersonalTeacherPageProps, TeachersPageTabs,} from '@/components/pages/personal-teacher-page/utils';// TODO: move context to separate folder, move types to separate folderexport interface TeacherContext { floatingCardShowed: boolean; setFloatingCardShowed: Dispatch<SetStateAction<boolean>>; teacher: Teacher;}export const teacherContext = createContext<TeacherContext>({ floatingCardShowed: false, setFloatingCardShowed: () => {}, teacher: {} as Teacher,});const PersonalTeacherPage: FC<PersonalTeacherPageProps> = ({ isLoading, isError, data, teacher, query, teacherId,}) => { const router = useRouter(); const { push } = router; const toast = useToast(); const [floatingCardShowed, setFloatingCardShowed] = useState(false); const { tab } = query; const [index, setIndex] = useState<TeachersPageTabs>( TeachersPageTabs.GENERAL, ); const handleChange = useTabState({ tab, router, setIndex }); useEffect(() => { if (isError) { toast.error('Куди ти лізеш, цієї людини не існує'); void push('/teachers'); } }, [isError, push]); if (!data) return null; return ( <teacherContext.Provider value={{ floatingCardShowed, setFloatingCardShowed, teacher, }} > <div className={styles['personal-teacher-page']}> {isLoading ? ( <div className={styles['personal-teacher-page-content']}> <div className={styles['loader']}> <Progress /> </div> </div> ) : ( !isError && ( <div className={styles['personal-teacher-page-content']}> <Breadcrumbs sx={{ margin: '16px 0px 16px 0px' }} //TODO move inline styles when refactor items={[ { label: 'Головна', href: '/', }, { label: 'Викладачі', href: '/teachers' }, { label: `${teacher.lastName} ${teacher.firstName} ${teacher.middleName}`, href: `/teachers/${teacherId}`, }, ]} /> <div className={styles['card-wrapper']}> <PersonalTeacherCard {...teacher} /> </div> <div className={styles['tabs']}> <PersonalTeacherTabs data={data} tabIndex={index} handleChange={handleChange} teacher={teacher} /> </div> </div> ) )} </div> </teacherContext.Provider> );};export default PersonalTeacherPage;\n"
     ]
    }
   ],
   "source": [
    "query = \"how do I do PersonalTeacherPage using React, Next, MUI for my website? Assume that I already have all the needed components\"\n",
    "completion = client.chat.completions.create(\n",
    "    model=fine_tuned_model_id,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"},\n",
    "        {\"role\": \"user\", \"content\": query}\n",
    "    ]\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the cook book please https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
